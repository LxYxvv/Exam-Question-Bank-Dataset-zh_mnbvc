{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e004081c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fc35813",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = {\"text\":[], \"label\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd15cef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "math_file_paths = glob.glob(\"../data/examination_paper_markdown\" + '/' + \"*.md\")\n",
    "\n",
    "for file_path in math_file_paths:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        train_dataset[\"text\"].append(f.read())\n",
    "        train_dataset[\"label\"].append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a07924dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "math_file_paths = glob.glob(\"../data/not_examination_paper_markdown\" + '/' + \"*.md\")\n",
    "\n",
    "for file_path in math_file_paths:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        train_dataset[\"text\"].append(f.read())\n",
    "        train_dataset[\"label\"].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd080e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.Dataset.from_dict(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9004b186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 2779\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10ce09a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = {\"text\":[], \"label\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "096b5584",
   "metadata": {},
   "outputs": [],
   "source": [
    "math_file_paths = glob.glob(\"../data/test_examination_paper_markdown\" + '/' + \"*.md\")\n",
    "\n",
    "for file_path in math_file_paths:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        test_dataset[\"text\"].append(f.read())\n",
    "        test_dataset[\"label\"].append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0eaac6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "math_file_paths = glob.glob(\"../data/test_not_examination_paper_markdown\" + '/' + \"*.md\")\n",
    "\n",
    "for file_path in math_file_paths:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        test_dataset[\"text\"].append(f.read())\n",
    "        test_dataset[\"label\"].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a185f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = datasets.Dataset.from_dict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50651696",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadict = datasets.DatasetDict({\n",
    "    \"train\":train_dataset,\n",
    "    \"test\":test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "29ca0b11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2779 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/387 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datadict.save_to_disk(\"./dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14724523",
   "metadata": {},
   "source": [
    "# 新增"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40e3c8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from paper_markdown_text_classifier import extract_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05a75b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/ran/.cache/huggingface/datasets/ranWang___parquet/ranWang--test_paper_textClassifier-c89de31317ad5101/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d958491c9e0540ad8c8c8a37da56fafd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datadict = datasets.load_dataset(\"ranWang/test_paper_textClassifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2104fd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datadict[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "51929741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'file_path'],\n",
       "    num_rows: 9536\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4dfa9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_file_name = {row[\"file_path\"].split(\"/\")[-1] for row in train_dataset}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b095d989",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 5644/5644 [00:01<00:00, 4920.52it/s]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "\n",
    "counterexamples = Path(\"./negative_file\").glob(\"**/*.doc*\")\n",
    "\n",
    "column = {\"text\":[], \"label\":[], \"file_path\": []}\n",
    "for file_path in tqdm(list(counterexamples)):\n",
    "    _, ext = os.path.splitext(file_path)\n",
    "    file_name = str(file_path).split(\"/\")[-1]\n",
    "    \n",
    "    if file_name in all_file_name:\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        text = extract_text(str(file_path), ext)\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    column[\"text\"].append(text)\n",
    "    column[\"label\"].append(0)\n",
    "    column[\"file_path\"].append(str(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34e7e0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1795/1795 [00:31<00:00, 56.50it/s]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "counterexamples = Path(\"./positive_file\").glob(\"**/*.doc*\")\n",
    "\n",
    "for file_path in tqdm(list(counterexamples)):\n",
    "    _, ext = os.path.splitext(file_path)\n",
    "    file_name = str(file_path).split(\"/\")[-1]\n",
    "    \n",
    "    if file_name in all_file_name:\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        text = extract_text(str(file_path), ext)\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "    column[\"text\"].append(text)\n",
    "    column[\"label\"].append(1)\n",
    "    column[\"file_path\"].append(str(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "049e8d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.concatenate_datasets([train_dataset, datasets.Dataset.from_dict(column)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dde5ada5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'file_path'],\n",
       "    num_rows: 10191\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd5a18ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadict[\"train\"] = train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "33dd291f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'file_path'],\n",
       "        num_rows: 387\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'file_path'],\n",
       "        num_rows: 10191\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc61d5f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/387 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/10191 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datadict.save_to_disk(\"./new_classification_datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3157beb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
